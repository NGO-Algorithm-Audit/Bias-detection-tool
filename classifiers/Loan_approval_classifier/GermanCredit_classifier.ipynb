{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "04ad3987",
   "metadata": {},
   "source": [
    "## Loan approval classifier\n",
    "In this notebooks a XGBoost loan approval classifier for credit application is trained. Overview of this notebook: \n",
    "1. Load data\n",
    "2. Explanatory data analysis\n",
    "3. Split features, labels, train, validate and test set\n",
    "4. Train XGBoost\n",
    "5. Make prediction\n",
    "6. Export predictions\n",
    "\n",
    "To build this classifier an online tutorial was consulted: https://towardsdatascience.com/fine-tuning-bert-for-text-classification-54e7df642894."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e914c397",
   "metadata": {},
   "source": [
    "### Load libraries and helper code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ca5800",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import random\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "# matplotlib\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# sklearn\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "# xgboost classifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# initialize dataset\n",
    "from helper_functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9243bc37",
   "metadata": {},
   "source": [
    "### 1. Load data\n",
    "Load one-hot encoded version of German Credit dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8776058",
   "metadata": {},
   "outputs": [],
   "source": [
    "gd = GermanDataset(\n",
    "    \n",
    "    # default pre-processing\n",
    "    custom_preprocessing=default_preprocessing\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a6ab68",
   "metadata": {},
   "source": [
    "Convert to pandas data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80aea605",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gd = gd.convert_to_dataframe()[0]\n",
    "df_gd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f561d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gd.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aafebdf5",
   "metadata": {},
   "source": [
    "### 2. Explanatory data analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a3a1384",
   "metadata": {},
   "source": [
    "Unbalanced dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7265d754",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[6, 3])\n",
    "plt.hist(df_gd[\"credit\"])\n",
    "plt.title(\"credit\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee3c7ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create bins and labels\n",
    "bins = [17,25,35,45,55,65,75]\n",
    "labels = [\"%s-%s\" %(bins[idx-1]+1,bins[idx]) for idx in range(1,len(bins))]\n",
    "\n",
    "# bin age colum\n",
    "b = pd.cut(df_gd['age'], bins=bins, labels=labels, include_lowest=False)\n",
    "\n",
    "# groupby age and credit column\n",
    "df_grouped_age = df_gd.groupby(['credit', b]).size().unstack(fill_value=0).stack().reset_index(name='count')\n",
    "df_grouped_age = df_grouped_age.groupby(['age','credit']).sum()\n",
    "df_grouped_age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93451c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_default_dict = {}\n",
    "bin_non_default_dict = {}\n",
    "\n",
    "# iterate through age groups to compute default percentage\n",
    "for label in labels:\n",
    "    \n",
    "    # number of defaulting applicants \n",
    "    n_default = df_grouped_age.loc[(label, 1.0)]['count']\n",
    "    n_non_default = df_grouped_age.loc[(label, 0.0)]['count']\n",
    "    \n",
    "    # append to dictionary\n",
    "    bin_default_dict[\"%s\" %label] = str('{0:.0f}'.format((n_default/(n_default+n_non_default))*100)) + \"%\"\n",
    "    bin_non_default_dict[\"%s\" %label] = str('{0:.0f}'.format((n_non_default/(n_default+n_non_default))*100)) + \"%\"\n",
    "\n",
    "bin_default_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f06de468",
   "metadata": {},
   "outputs": [],
   "source": [
    "color_dark = \"#0043CE\"\n",
    "color_light = \"#D9D9D9\"\n",
    "\n",
    "# plot\n",
    "fig, ax = plt.subplots(figsize=(15,10))\n",
    "df_grouped_age.unstack().plot(kind='barh', stacked=True, ax=ax, color=[color_dark,color_light], edgecolor='k')\n",
    "\n",
    "# x-axis\n",
    "ax.set_xlabel(\"Frequency\", fontsize=20, fontweight='bold', color=color_dark)\n",
    "ax.tick_params(axis='both', which='major', labelsize=16)\n",
    "ax.set_xlim([0,430])\n",
    "ax.xaxis.set_label_coords(0.5, -0.1)\n",
    "\n",
    "# y-axis\n",
    "ax.set_ylabel(\"Age group\", fontsize=20, fontweight='bold', color=color_dark)\n",
    "ax.yaxis.set_label_coords(-0.1, 0.5)\n",
    "\n",
    "# iterate through labels to annotate text\n",
    "for i in range(0,6):\n",
    "    label = labels[i]\n",
    "    x_coord = df_grouped_age.loc[label]['count'].sum()\n",
    "    y_coord = i\n",
    "    \n",
    "    # annotate text\n",
    "    plt.text(x_coord+17.5, y_coord+0.05, bin_non_default_dict[label], ha=\"center\", va=\"bottom\", color=color_dark, fontsize=18, fontweight=\"bold\")\n",
    "    plt.text(x_coord+17.5, y_coord-0.25, bin_default_dict[label], ha=\"center\", va=\"bottom\", color='#6B6666', fontsize=18, fontweight=\"bold\")\n",
    "\n",
    "# legend\n",
    "ax.legend(['No default','Default'], fontsize=18)\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f04fd821",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create bins and labels\n",
    "bins = [0,1]\n",
    "labels = [0.0]\n",
    "\n",
    "# bin sex colum\n",
    "b = pd.cut(df_gd['sex'], bins=bins, labels=labels, include_lowest=False)\n",
    "\n",
    "# groupby sex and credit column\n",
    "df_grouped_sex = df_gd.groupby(['credit', 'sex']).size().unstack(fill_value=0).stack().reset_index(name='count')\n",
    "df_grouped_sex = df_grouped_sex.groupby(['sex','credit']).sum()\n",
    "df_grouped_sex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96315101",
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_default_sex_dict = {}\n",
    "bin_non_default_sex_dict = {}\n",
    "\n",
    "labels = [0.0,1.0]\n",
    "\n",
    "# iterate through age groups to compute default percentage\n",
    "for label in labels:\n",
    "    \n",
    "    # number of defaulting applicants \n",
    "    n_default = df_grouped_sex.loc[(label, 1.0)]['count']\n",
    "    n_non_default = df_grouped_sex.loc[(label, 0.0)]['count']\n",
    "    \n",
    "    # append to dictionary\n",
    "    bin_default_sex_dict[\"%s\" %label] = str('{0:.0f}'.format((n_default/(n_default+n_non_default))*100)) + \"%\"\n",
    "    bin_non_default_sex_dict[\"%s\" %label] = str('{0:.0f}'.format((n_non_default/(n_default+n_non_default))*100)) + \"%\"\n",
    "\n",
    "bin_default_sex_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19024728",
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_non_default_sex_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29577d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "fig, ax = plt.subplots(figsize=(15,10))\n",
    "df_grouped_sex.unstack().plot(kind='barh', stacked=True, ax=ax, color=[color_dark,color_light], edgecolor='k')\n",
    "\n",
    "# x-axis\n",
    "ax.set_xlabel(\"Frequency\", fontsize=20, fontweight='bold', color=color_dark)\n",
    "ax.tick_params(axis='both', which='major', labelsize=16)\n",
    "ax.xaxis.set_label_coords(0.5, -0.1)\n",
    "ax.set_xlim([0,790])\n",
    "\n",
    "# y-axis\n",
    "ax.set_ylabel(\"Sex\", fontsize=20, fontweight='bold', color=color_dark)\n",
    "ax.set_yticklabels(['male','female'])\n",
    "ax.yaxis.set_label_coords(-0.1, 0.5)\n",
    "\n",
    "# iterate through labels to annotate text\n",
    "for i in range(0,2):\n",
    "    label = labels[i]\n",
    "    x_coord = df_grouped_sex.loc[label]['count'].sum()\n",
    "    y_coord = i\n",
    "    \n",
    "    # annotate text\n",
    "    plt.text(x_coord+35, y_coord+0.1, bin_non_default_sex_dict[\"%s\" %label], ha=\"center\", va=\"bottom\", color=color_dark, fontsize=18, fontweight=\"bold\")\n",
    "    plt.text(x_coord+35, y_coord-0.15, bin_default_sex_dict[\"%s\" %label], ha=\"center\", va=\"bottom\", color='#6B6666', fontsize=18, fontweight=\"bold\")\n",
    "\n",
    "# legend\n",
    "ax.legend(['No default','Default'], fontsize=18)\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c399ef43",
   "metadata": {},
   "source": [
    "### 3. Split features, labels, train, validate and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b7a58a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_gd.drop('credit', axis=1)\n",
    "y = df_gd['credit']\n",
    "\n",
    "# Splitting X and y into train and test version\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f9c82ce",
   "metadata": {},
   "source": [
    "### 4. Train XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac3cddb6",
   "metadata": {},
   "source": [
    "Initialize model and specify model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25373f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgbc = XGBClassifier()\n",
    "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
    "       colsample_bynode=1, colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
    "       max_delta_step=0, max_depth=3, min_child_weight=1, missing=None,\n",
    "       n_estimators=100, n_jobs=1, nthread=None,\n",
    "       objective='multi:softprob', random_state=0, reg_alpha=0,\n",
    "       reg_lambda=1, scale_pos_weight=1, seed=None, silent=None,\n",
    "       subsample=1, verbosity=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a92f90c",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgbc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c735f87",
   "metadata": {},
   "source": [
    "### 5. Make predictions\n",
    "Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf8619bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = xgbc.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb14169b",
   "metadata": {},
   "source": [
    "Merging predictions to dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "131a8ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting y_hat from np to df\n",
    "predictions_col = pd.DataFrame(index=X_test.index)\n",
    "predictions_col['predicted_class'] = y_hat.tolist()\n",
    "predictions_col['true_class'] = y_test.tolist()\n",
    "\n",
    "# Calculating the errors with the absolute value \n",
    "predictions_col['errors'] = abs(predictions_col['predicted_class'] - predictions_col['true_class'])\n",
    "\n",
    "# Adding predictions to test data\n",
    "entire_dataset = pd.merge(X_test, predictions_col, left_index = True, right_index = True)\n",
    "entire_dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b3e578c",
   "metadata": {},
   "source": [
    "#### Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "121c7203",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = entire_dataset[\"predicted_class\"]\n",
    "true = entire_dataset[\"true_class\"]\n",
    "\n",
    "cm = confusion_matrix(true, predictions, labels=[1, 0], normalize='pred')\n",
    "cmap0 = mpl.colors.LinearSegmentedColormap.from_list(\n",
    "        'unevently divided', ['#618EC7','#fffde4'])\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['True', 'False'])\n",
    "disp.plot(cmap=cmap0)\n",
    "\n",
    "print('Acc: ', accuracy_score(predictions,true))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fb41b51",
   "metadata": {},
   "source": [
    "### 6. Export data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba6ddd5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "entire_dataset.to_csv('./pred_XGBoost.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
