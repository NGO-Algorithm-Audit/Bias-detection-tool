{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab5d390b",
   "metadata": {},
   "source": [
    "## Twitter API data collection\n",
    "In this notebook, data from the Twitter API is collected for the users mentioned in the Twitter16\\* data set. The following user features are collected:\n",
    "- `verified profile`\n",
    "- `account age`\n",
    "- `#followers`\n",
    "- `#tweets`.\n",
    "\n",
    "The following content (tweet) features are collected:\n",
    "- `#favourites`\n",
    "- `#retweets`\n",
    "- `#replies`.\n",
    "- `length`\n",
    "- `#hashs`\n",
    "- `#mentions`\n",
    "- `#URLs`.\n",
    "\n",
    "As defined by Voshughi\\*, `user_engagement` is defined as (`#tweets` + `#retweets` + `#replies` + `#favourites`) / `account age`. \n",
    "\n",
    "The `sentiment_score` is based on the VADER sentiment analysis tool\\*\\*.\n",
    "\n",
    "\\* Vosoughi, S., Roy, D., and Aral, S.: The spread of true and false news online. *Science* 359, 6380 (2018), 1146â€“1151.\n",
    "\n",
    "\\*\\* https://github.com/cjhutto/vaderSentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95c92fb9",
   "metadata": {},
   "source": [
    "### Overview of notebook:\n",
    "1. Load Twitter16 data\n",
    "2. Content features\n",
    "3. User features (Twitter API)\n",
    "4. User engagement metric\n",
    "5. Sentiment score\n",
    "6. Export dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd363ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import tweepy\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import vaderSentiment\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf3483fe",
   "metadata": {},
   "source": [
    "### 1. Load Twitter16 data \n",
    "#### Load labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dd26631",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data\n",
    "df1 = pd.read_csv('src/Twitter16/label.txt', sep=\":\", header=None) \n",
    "df1.columns = [\"label\", \"tweet_id\"]\n",
    "\n",
    "# filter true and false labels\n",
    "df1 = df1.loc[(df1['label'] == 'false') | (df1['label'] == 'true')]\n",
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b61683",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping_dict = {'false': 1, 'true': 0}\n",
    "df1['label'] = df1['label'].map(mapping_dict)\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c3272a3",
   "metadata": {},
   "source": [
    "#### Load tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf86e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data\n",
    "df2 = pd.read_csv('src/Twitter16/source_tweets.txt', sep=\"\t\", header=None)\n",
    "df2.columns = [\"tweet_id\", \"tweet\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "889813e1",
   "metadata": {},
   "source": [
    "#### Merge dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb30dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(df1, df2, on='tweet_id')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbe07f3b",
   "metadata": {},
   "source": [
    "### 2. Determine content features\n",
    "#### #URLs, #mentions, #hashtags and length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "290177ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def n_URLs(row):\n",
    "    return(row.count('URL'))\n",
    "\n",
    "def n_mentions(row):\n",
    "    return(row.count('@'))\n",
    "\n",
    "def n_hashs(row):\n",
    "    return(row.count('#'))\n",
    "\n",
    "df['length']= df.apply(lambda x: len(x['tweet']), axis=1)\n",
    "df['#URLs'] = df.apply(lambda x: n_URLs(x['tweet']), axis=1)\n",
    "df['#mentions'] = df.apply(lambda x: n_mentions(x['tweet']), axis=1)\n",
    "df['#hashs'] = df.apply(lambda x: n_hashs(x['tweet']), axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f5c4941",
   "metadata": {},
   "source": [
    "#### Add new columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2755c2a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['verified'] = [0]*df.shape[0]\n",
    "df['#followers'] = [0]*df.shape[0]\n",
    "\n",
    "# user engagement\n",
    "df['#replies'] = [0]*df.shape[0]\n",
    "df['#retweets'] = [0]*df.shape[0]\n",
    "df['#tweets'] = [0]*df.shape[0]\n",
    "df['#favourites'] = [0]*df.shape[0]\n",
    "df['account_age'] = [0]*df.shape[0]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f2390e",
   "metadata": {},
   "source": [
    "### 3. User features (Twitter API)\n",
    "#### Connect to Twitter API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b2129dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# twitter API\n",
    "api_key = \"DFzJ0JdiaB1R2HdNvoLd1zed6\"\n",
    "api_secrets = \"eN6ifjX1odIYy2rae8Gbe25jVWihwk7Z40nvFJ1pLDKbWXnh1j\"\n",
    "access_token = \"1542497605141385218-XVZ9BRiWvNeaOAvPxOOJ9SfmMAnqbW\"\n",
    "access_secret = \"vNPqtgIs5ruEUr8ZasSTNHXmn0u3dXVYjSCMxfXdi5Fcx\"\n",
    "bearer_token = \"AAAAAAAAAAAAAAAAAAAAAIWNkgEAAAAAsNlmvJOaWNjYhDUacKToVogtmw0%3DBv0ZF3lCyKSwQUl7ePH33CHkiXhq5DypPY960jvG3KNCOIraOv\"\n",
    " \n",
    "# Authenticate to Twitter\n",
    "auth = tweepy.OAuthHandler(api_key,api_secrets)\n",
    "auth.set_access_token(access_token,access_secret)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d0f6298",
   "metadata": {},
   "source": [
    "#### Collect retweet and reply count in two parts to prevent API overload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cacae0ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first 200 requests\n",
    "j=0\n",
    "for i in range(0,200):\n",
    "    tweet_id = df.iloc[i,1]\n",
    "    try:\n",
    "        # connect to API\n",
    "        client = tweepy.Client(bearer_token=bearer_token)\n",
    "        client_result = client.get_tweet(tweet_id, \\\n",
    "              tweet_fields=[\"public_metrics\"])\n",
    "        tweet = client_result.data\n",
    "        df.iloc[i,9] = tweet.public_metrics['reply_count']\n",
    "        df.iloc[i,10] = tweet.public_metrics['retweet_count']\n",
    "    except Exception as e: \n",
    "#         print(e)\n",
    "        j+=1\n",
    "        pass \n",
    "print(\"exceptions: \",j)\n",
    "\n",
    "# wait 15+ minutes\n",
    "time.sleep(60*16)\n",
    "\n",
    "# second 200+ requests\n",
    "k=0\n",
    "for i in range(200,df.shape[0]):\n",
    "    tweet_id = df.iloc[i,1]\n",
    "    try:\n",
    "        client = tweepy.Client(bearer_token=bearer_token)\n",
    "        client_result = client.get_tweet(tweet_id, \\\n",
    "        tweet_fields=[\"public_metrics\"])\n",
    "        tweet = client_result.data\n",
    "        df.iloc[i,9] = tweet.public_metrics['reply_count']\n",
    "        df.iloc[i,10] = tweet.public_metrics['retweet_count']\n",
    "    except Exception as e: \n",
    "#         print(e)\n",
    "        k+=1\n",
    "        pass \n",
    "print(\"exceptions: \",k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c54208f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cfb5ebd",
   "metadata": {},
   "source": [
    "#### Collect verified, #followers, #tweets and #favourites in two parts to prevent API overload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c3bc29",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# first 200 requests\n",
    "l=0\n",
    "for i in range(0,200):\n",
    "    tweet_id = df.iloc[i,1]\n",
    "    try:\n",
    "        # connect to API\n",
    "        api = tweepy.API(auth)\n",
    "        status= api.get_status(id=tweet_id)\n",
    "#         print(status)\n",
    "        df.iloc[i,7] = status._json['user']['verified']\n",
    "        df.iloc[i,8] = status._json['user']['followers_count']\n",
    "        df.iloc[i,11] = status._json['user']['statuses_count']\n",
    "        df.iloc[i,12] = status._json['favorite_count']\n",
    "        \n",
    "        # account age\n",
    "        account_created = status._json['user']['created_at']\n",
    "        tweet_created = status._json['created_at']\n",
    "        t1 = '-'.join(list(account_created.split(' ')[i] for i in [1,2,5]))\n",
    "        t2 = '-'.join(list(tweet_created.split(' ')[i] for i in [1,2,5]))\n",
    "        FMT = '%b-%d-%Y'\n",
    "        tdelta = datetime.strptime(t2, FMT) - datetime.strptime(t1, FMT)\n",
    "        df.iloc[i,13] = abs(tdelta.days)\n",
    "        \n",
    "    except:\n",
    "        l+=1\n",
    "        pass \n",
    "    \n",
    "# wait 15+ minutes\n",
    "time.sleep(60*16)\n",
    "    \n",
    "# second 200+ requests\n",
    "m=0\n",
    "for i in range(200,df.shape[0]):\n",
    "    tweet_id = df.iloc[i,1]\n",
    "    try:\n",
    "        # connect to API\n",
    "        api = tweepy.API(auth)\n",
    "        status= api.get_status(id=tweet_id)\n",
    "#         print(status)\n",
    "        df.iloc[i,7] = status._json['user']['verified']\n",
    "        df.iloc[i,8] = status._json['user']['followers_count']\n",
    "        df.iloc[i,11] = status._json['user']['statuses_count']\n",
    "        df.iloc[i,12] = status._json['favorite_count']\n",
    "        \n",
    "        # account age\n",
    "        account_created = status._json['user']['created_at']\n",
    "        tweet_created = status._json['created_at']\n",
    "        t1 = '-'.join(list(account_created.split(' ')[i] for i in [1,2,5]))\n",
    "        t2 = '-'.join(list(tweet_created.split(' ')[i] for i in [1,2,5]))\n",
    "        FMT = '%b-%d-%Y'\n",
    "        tdelta = datetime.strptime(t2, FMT) - datetime.strptime(t1, FMT)\n",
    "        df.iloc[i,13] = abs(tdelta.days)\n",
    "        \n",
    "    except:\n",
    "        m+=1\n",
    "        pass "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a4b9dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(l)\n",
    "print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f08fb1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea092e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop 96 non-existing profiles\n",
    "no_exist_idx = df.loc[(df['#replies'] == 0) & (df['#retweets'] == 0) & (df['verified'] == 0) & (df['#followers'] == 0) & (df['#tweets'] == 0) & (df['#favourites'] == 0)].index\n",
    "df = df.drop(index=no_exist_idx)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7533674b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a3cdf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# map verified profile column\n",
    "mapping2_dict = {True: 1, False: 0}\n",
    "df2['verified'] = df2['verified'].map(mapping2_dict)\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "308f1c4e",
   "metadata": {},
   "source": [
    "### 4. User engagement metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "985bbed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['user_engagement'] = (df2['#tweets']+df2['#retweets']+df2['#replies']+df2['#favourites'])/df2['account_age']\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f76d62b2",
   "metadata": {},
   "source": [
    "### 5. Sentiment score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade77ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# new column\n",
    "df2['sentiment_score'] = [0]*df2.shape[0]\n",
    "\n",
    "# compute sentiment score for tweets\n",
    "tweets = df2['tweet'].to_list()\n",
    "\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "for i in range(0,df2.shape[0]):\n",
    "    tweet = df2.iloc[i,2]\n",
    "    vs = analyzer.polarity_scores(tweet)\n",
    "    df2.iloc[i,15] = vs['compound']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c90451eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab1eba74",
   "metadata": {},
   "source": [
    "### 6. Export dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e768d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.to_csv('./twitter16_full.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
